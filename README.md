# my_openai_api

éƒ¨ç½²ä½ è‡ªå·±çš„**OpenAI** æ ¼å¼apiğŸ˜†ï¼ŒåŸºäº**flask, transformers** (ä½¿ç”¨ **Baichuan2-13B-Chat-4bits** æ¨¡å‹ï¼Œå¯ä»¥è¿è¡Œåœ¨å•å¼ Tesla T4æ˜¾å¡) ï¼Œå®ç°ä»¥ä¸‹**OpenAI**æ¥å£ï¼š
- **Chat**   /v1/chat/completions
- **Models**   /v1/models
- **Completions**   /v1/completions

åŒæ—¶å®ç°æ¥å£ç›¸åº”çš„STREAMINGæ¨¡å¼ï¼Œä¿è¯åœ¨**langchain**ä¸­åŸºç¡€è°ƒç”¨

## èµ·å› 

ç›®å‰Baichuan2-13B-Chat int4é‡åŒ–åå¯åœ¨å•å¼ tesla T4æ˜¾å¡è¿è¡Œï¼Œå¹¶ä¸”æ•ˆæœå’Œé€Ÿåº¦è¿˜å¯ä»¥ï¼Œå¯ä»¥å’Œgpt-3.5åª²ç¾ã€‚  
- **Baichuan2-13B-Chat-4bits**ï¼š[https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits)

## æœ€ä½é…ç½®

éœ€è¦16gæ˜¾å­˜ï¼Œå¦‚æœä¸»æœºæ˜¾å­˜ä¸å¤Ÿå¯ä»¥è€ƒè™‘è…¾è®¯äº‘çš„æ´»åŠ¨ï¼Œ60å—é’±15å¤©32gå†…å­˜ã€T4æ˜¾å¡çš„ä¸»æœºï¼Œéå¸¸åˆ’ç®—ğŸ˜ï¼Œå¯ä»¥è·‘åŠ¨baichuan2-13b-chat-4bitsã€‚  
  
<a href="https://s2.loli.net/2023/09/25/q7C4jdJocwym1fh.png" target="_blank"><img src="https://s2.loli.net/2023/09/25/q7C4jdJocwym1fh.png" width="60%"></a>  

åœ°å€: [https://cloud.tencent.com/act/pro/gpu-study](https://cloud.tencent.com/act/pro/gpu-study)  

å¦‚æœæƒ³è¦æœ¬åœ°è¿è¡Œï¼ŒT4æ˜¾å¡ä»·æ ¼åœ¨5600å…ƒå·¦å³ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘2080tié­”æ”¹22gç‰ˆæœ¬ï¼ŒæŸå®åªè¦2600å…ƒå·¦å³ ğŸ¤“ï¸ã€‚

## å®‰è£…

1. ä¸‹è½½ä»£ç 
```
git clone https://github.com/billvsme/my_openai_api.git
```
2. ä¸‹è½½Baichuan2-13B-Chat-4bitsæ¨¡å‹
```
cd my_openai_api

git lfs install #éœ€è¦å…ˆå®‰è£…å¥½git-lfs
git clone https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits
```
3. å®‰è£…venvç¯å¢ƒ
```
mkdir ~/.venv
python -m venv ~/.venv/ai
. ~/.venv/ai/bin/activate

pip install -r requirements.txt
```

## å¯åŠ¨
```
python my_openai_api.py
æˆ–è€…
gunicorn -b 0.0.0.0:5000 --workers=1  my_openai_api:app
```

## æ–‡æ¡£
å®ç°äº†openaiçš„models, chat, moderations 3ä¸ªæ¥å£  
å¯ä»¥å‚è€ƒhttps://platform.openai.com/docs/api-reference/chat
```
æ‰“å¼€ http://127.0.0.1:5000/apidocs/
```

![github_my_open_api_002.png](https://s2.loli.net/2023/09/25/o8I5GE3ONfhSaqz.png)


## ä½¿ç”¨

### langchain

æ›¿æ¢openai_base_api
```
# coding: utf-8
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.schema import (
    HumanMessage,
)

openai_api_base = "http://127.0.0.1:5000/v1"
openai_api_key = "test"

# /v1/chat/completionsæµå¼å“åº”
chat_model = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], openai_api_base=openai_api_base, openai_api_key=openai_api_key)
resp = chat_model([HumanMessage(content="ç»™æˆ‘ä¸€ä¸ªdjango adminçš„demoä»£ç ")])
chat_model.predict("ä½ å«ä»€ä¹ˆ?")

# /v1/chat/completionsæ™®é€šå“åº”
chat_model = ChatOpenAI(openai_api_base=openai_api_base, openai_api_key=openai_api_key)
resp = chat_model.predict("ç»™æˆ‘ä¸€ä¸ªdjango adminçš„demoä»£ç ")
print(resp)

# /v1/completionsæµå¼å“åº”
llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_base=openai_api_base, openai_api_key=openai_api_key)
llm("ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—->")

# /v1/completionsæ™®é€šå“åº”
llm = OpenAI(openai_api_base=openai_api_base, openai_api_key=openai_api_key)
print(llm("ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—->"))
```

### ChatGPT Next 

è®¾ç½®ä¸­æŠŠæ¥å£åœ°å€ä¿®æ”¹ä¸ºä½ çš„ipï¼Œå¦‚æœéƒ¨ç½²ç½‘é¡µä¸ºhttpsï¼Œæ³¨æ„åœ¨Chromeè®¾ç½®ä¸­â€œä¸å®‰å…¨å†…å®¹â€é€‰æ‹©â€œå…è®¸â€

<a href="https://sm.ms/image/8eMUw6sHXP9QBmj" target="_blank"><img src="https://s2.loli.net/2023/09/25/8eMUw6sHXP9QBmj.png" width="50%"></a>

### OpenAI Translator

è®¾ç½®ä¸­æŠŠapi urlä¿®æ”¹ä¸ºä½ çš„ip  

<a href="https://s2.loli.net/2023/09/25/q7C4jdJocwym1fh.png" target="_blank"><img src="https://s2.loli.net/2023/09/25/jbqNs1kBlJHv4K6.png" width="60%"></a>  


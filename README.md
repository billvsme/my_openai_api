# my_openai_api
åœ¨è‡ªå·±çš„ç”µè„‘ä¸Šéƒ¨ç½²æ¨¡å‹å…¼å®¹openaiæ¥å£ï¼Œç›®å‰baichuan2-13b-chat-4bitsåœ¨å•å¼ tesla t4æ˜¾å¡å°±å¯ä»¥è·‘åŠ¨ï¼Œå¹¶ä¸”æ•ˆæœå’Œé€Ÿåº¦ä¹Ÿè¿˜å¯ä»¥ï¼Œå¯ä»¥å’Œgpt-3.5åª²ç¾ã€‚
æ­¤é¡¹ç›®åŸºäºflask, transformså•ä¸ªæ–‡ä»¶å®ç°openaiæ¥å£(models, chat, moderationsåŒ…å«æµå¼å“åº”)ï¼Œå¯ä»¥ä¿è¯langchainåŸºç¡€è°ƒç”¨ã€‚
## æœ€ä½é…ç½®
éœ€è¦16gæ˜¾å­˜ï¼Œå¦‚æœä¸»æœºæ˜¾å­˜ä¸å¤Ÿå¯ä»¥è€ƒè™‘è…¾è®¯äº‘çš„æ´»åŠ¨ï¼Œ60å—é’±15å¤©32gå†…å­˜ã€t4æ˜¾å¡çš„ä¸»æœºï¼Œéå¸¸åˆ’ç®—ğŸ˜ï¼Œå¯ä»¥è·‘åŠ¨baichuan2-13b-chat-4bitsã€‚  
  
<a href="https://s2.loli.net/2023/09/25/q7c4jdjocwym1fh.png" target="_blank"><img src="https://s2.loli.net/2023/09/25/q7c4jdjocwym1fh.png" width="60%"></a>  

åœ°å€: [https://cloud.tencent.com/act/pro/gpu-study](https://cloud.tencent.com/act/pro/gpu-study)  

å¦‚æœæƒ³è¦æœ¬åœ°è¿è¡Œï¼Œt4æ˜¾å¡ä»·æ ¼åœ¨5600å…ƒå·¦å³ã€‚å¦‚æœå«Œè´µï¼Œå¯ä»¥è€ƒè™‘2080tié­”æ”¹22gç‰ˆæœ¬ï¼ŒæŸå®2600å…ƒå·¦å³ ğŸ¤“ï¸ã€‚
## å®‰è£…
1. ä¸‹è½½ä»£ç 
```
git clone https://github.com/billvsme/my_openai_api.git
```
2. ä¸‹è½½baichuan2-13b-chat-4bitsæ¨¡å‹
```
cd my_openai_api
git clone https://huggingface.co/baichuan-inc/baichuan2-7b-chat-4bits  # éœ€è¦å…ˆå®‰è£…å¥½hfsï¼Œ git lfs install
```
3. å®‰è£…venvç¯å¢ƒ
```
mkdir ~/.venv
python -m venv ~/.venv/ai
. ~/.venv/ai/bin/activate

pip install -r requirements.txt
```
## å¯åŠ¨
```
python my_openai_api.py
æˆ–è€…
gunicorn -b 0.0.0.0:5000 --workers=1  my_openai_api:app
```
## æ–‡æ¡£
å®ç°äº†openaiçš„models, chat, moderations 3ä¸ªæ¥å£  
å¯ä»¥å‚è€ƒhttps://platform.openai.com/docs/api-reference/chat
```
æ‰“å¼€ http://127.0.0.1:5000/apidocs/
```
  
<a href="https://s2.loli.net/2023/09/25/o8i5ge3onfhsaqz.png" target="_blank"><img src="https://s2.loli.net/2023/09/25/o8i5ge3onfhsaqz.png", width="60%" ></a>  

## ä½¿ç”¨
æ›¿æ¢openai_base_api, ä»¥langchainä¸ºä¾‹
```
# coding: utf-8
from langchain.llms import openai
from langchain.chat_models import chatopenai
from langchain.callbacks.streaming_stdout import streamingstdoutcallbackhandler
from langchain.schema import (
    humanmessage,
)

openai_api_base = "http://127.0.0.1:5000/v1"
openai_api_key = "test"

# /v1/chat/completionsæµå¼å“åº”
chat_model = chatopenai(streaming=true, callbacks=[streamingstdoutcallbackhandler()], openai_api_base=openai_api_base, openai_api_key=openai_api_key)
resp = chat_model([humanmessage(content="ç»™æˆ‘ä¸€ä¸ªdjango adminçš„demoä»£ç ")])
chat_model.predict("ä½ å«ä»€ä¹ˆ?")

# /v1/chat/completionsæ™®é€šå“åº”
chat_model = chatopenai(openai_api_base=openai_api_base, openai_api_key=openai_api_key)
resp = chat_model.predict("ç»™æˆ‘ä¸€ä¸ªdjango adminçš„demoä»£ç ")
print(resp)

# /v1/completionsæµå¼å“åº”
llm = openai(streaming=true, callbacks=[streamingstdoutcallbackhandler()], temperature=0, openai_api_base=openai_api_base, openai_api_key=openai_api_key)
llm("ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—->")

# /v1/completionsæ™®é€šå“åº”
llm = openai(openai_api_base="http://43.134.77.153:5000/v1", openai_api_key=openai_api_key)
print(llm("ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—->"))
```
  
openai translator è®¾ç½®ä¸­æŠŠapi urlä¿®æ”¹ä¸ºä½ çš„ip  

<a href="https://s2.loli.net/2023/09/25/jbqns1kbljhv4k6.png" target="_blank"><img src="https://s2.loli.net/2023/09/25/jbqns1kbljhv4k6.png" width="60%"></a>  

